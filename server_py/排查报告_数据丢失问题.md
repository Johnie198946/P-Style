# 排查报告：数据丢失问题（4步排查法）

## 排查时间
2025-01-XX

## 排查目标
按照用户提供的 4 步排查法，检查新的数据结构（`spatial_analysis`、`ref_visual_subject_box`、`ref_visual_mass_polygon`）是否被正确处理。

---

## ✅ 步骤 2：JSON 解析清洗逻辑（已完成）

### 问题发现
- **位置**：`server_py/app/routes/analyze.py` 第 451 行
- **问题**：代码直接使用 `json.loads(gemini_response)`，没有先调用 `clean_json_response` 清洗
- **风险**：如果 Gemini 返回的 JSON 包含 Markdown 代码块标记（如 ````json`），会导致解析失败

### 修复内容
1. **添加完整原始输出日志**：
   ```python
   logger.info("========== GEMINI RAW OUTPUT START ==========")
   logger.info(f"Part1 Gemini 完整原始响应:\n{gemini_response}")
   logger.info("========== GEMINI RAW OUTPUT END ==========")
   ```

2. **使用 clean_json_response 清洗**：
   ```python
   from ..services.prompt_template import clean_json_response
   cleaned_response = clean_json_response(gemini_response)
   gemini_json = json.loads(cleaned_response)
   ```

3. **添加字段验证日志**：
   - 检查 `spatial_analysis` 字段是否存在
   - 检查 `ref_visual_subject_box` 字段是否存在（破坏性命名）
   - 检查 `ref_visual_mass_polygon` 字段是否存在

### 判断标准
- ✅ 如果控制台打印出的 RAW OUTPUT 里有 `ref_visual_subject_box` 和 `ref_visual_mass_polygon`，说明 Prompt 成功了
- ⚠️ 如果 RAW OUTPUT 里依然是旧结构，那才是 Prompt 或缓存的问题

---

## ✅ 步骤 1：Pydantic 数据模型（已完成）

### 问题发现
- **位置**：`server_py/app/schemas/analysis_schemas.py` 第 51 行
- **问题**：`PhotoReviewStructuredSchema` 只有 `overlays` 字段，但没有 `spatial_analysis` 字段
- **风险**：虽然使用了 `model_config = {"extra": "allow"}`，但为了明确性和类型安全，应该显式定义新字段

### 修复内容
在 `PhotoReviewStructuredSchema` 中添加 `spatial_analysis` 字段：
```python
# 【新增】spatial_analysis 字段：空间分析大一统（最新格式）
# 包含 ref_visual_mass_polygon、ref_overlays、user_overlays
# 注意：这是 Prompt 模板的新结构，用于解决 Gemini 跳过 visual_mass 的问题
spatial_analysis: Optional[Dict[str, Any]] = Field(default_factory=dict, description="空间分析数据（包含 visual_mass 和 overlays）")
```

### 判断标准
- ✅ Pydantic 模型现在支持 `spatial_analysis` 字段
- ✅ 不会因为字段名不匹配而过滤掉新字段

---

## ✅ 步骤 4：Gemini 参数配置（已完成）

### 问题发现
- **位置**：`server_py/app/services/gemini_service.py` 第 98-116 行
- **问题**：代码使用 `response_mime_type` 但没有设置 `temperature` 和 `top_p`
- **风险**：如果 `temperature` 设置得太高（> 0.7），Gemini 会变得"更有创造力"，从而忽略 Prompt 中的格式限制

### 修复内容
添加 `generation_config` 配置（待 SDK 确认支持方式）：
```python
# 【步骤4：Gemini 参数配置】设置 temperature 和 top_p（对于结构化输出任务，越低越好）
generation_config = {
    "temperature": 0.2,  # 保持冷静，不要胡编乱造（对于结构化输出任务，越低越好）
    "top_p": 0.95,
    "top_k": 64,
    "max_output_tokens": 8192,
}
logger.info(f"Gemini generation_config: temperature=0.2, top_p=0.95 (待 SDK 确认支持方式)")
# TODO: 如果 SDK 支持，取消下面的注释
# config_params["generation_config"] = generation_config
```

### 判断标准
- ⚠️ 当前代码已添加配置，但需要等待 SDK 确认支持方式
- ✅ 日志会记录配置信息，便于后续调试

---

## ⏳ 步骤 3：前端数据绑定（待用户验证）

### 排查方法
1. 打开浏览器的开发者工具 (F12) -> Network (网络)
2. 找到 API 请求（比如 `/api/analyze/part1`）
3. 点击 Response (响应) 标签
4. 查看浏览器收到的 JSON 结构

### 判断标准
- ✅ 如果 Network 里显示的 JSON 是新的结构（包含 `spatial_analysis` 等），那么后端和 Prompt 都是好的，只需要去改前端代码来适配新结构
- ⚠️ 如果 Network 里显示的 JSON 是旧结构，那么需要继续排查后端

---

## 总结

### 已完成的修复
1. ✅ **步骤 2**：添加了完整的 Gemini 原始输出日志，使用 `clean_json_response` 清洗 JSON，并添加字段验证
2. ✅ **步骤 1**：在 Pydantic Schema 中添加了 `spatial_analysis` 字段
3. ✅ **步骤 4**：添加了 Gemini `generation_config` 配置（待 SDK 确认支持方式）

### 待用户验证
- ⏳ **步骤 3**：前端数据绑定（需要用户在浏览器中查看 Network 响应）

### 下一步行动
1. **运行一次分析请求**，查看日志中的 "GEMINI RAW OUTPUT" 部分
2. **检查日志中的字段验证结果**（是否包含 `spatial_analysis`、`ref_visual_subject_box`、`ref_visual_mass_polygon`）
3. **在浏览器中查看 Network 响应**，确认后端返回的数据结构
4. **如果 RAW OUTPUT 正确但 Network 响应不正确**，检查 `analysis_formatter.py` 的数据转换逻辑
5. **如果 Network 响应正确但前端显示不正确**，检查前端的数据适配逻辑

---

## 关键日志位置

### 后端日志
- **Gemini 原始输出**：`========== GEMINI RAW OUTPUT START ==========`
- **字段验证**：`✅ 清洗后的 JSON 包含 'spatial_analysis' 字段`
- **保存文件**：`/tmp/gemini_response_part1_<timestamp>.json`

### 前端调试
- **Network 面板**：查看 `/api/analyze/part1` 的 Response
- **Console 面板**：查看前端的数据适配日志

---

## 注意事项

1. **SDK 支持**：`generation_config` 的配置需要等待 `google-genai` SDK 确认支持方式
2. **向后兼容**：所有修复都保持了向后兼容性，不会影响旧格式的数据
3. **日志级别**：RAW OUTPUT 日志使用 `logger.info`，确保在生产环境中也能看到（如果日志级别允许）

